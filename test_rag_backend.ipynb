{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d78d6cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfbfde1",
   "metadata": {},
   "source": [
    "## dependencies\n",
    "- %pip install langchain-community faiss-cpu\n",
    "- %pip install -qU langchain_community pypdf\n",
    "- %pip install sentence-transformers\n",
    "- %pip install openai\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1071e9eb",
   "metadata": {},
   "source": [
    "# Load PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fc51ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"496.pdf\")\n",
    "document = loader.load()\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17268669",
   "metadata": {},
   "source": [
    "# Chunking Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "220f682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6facbe",
   "metadata": {},
   "source": [
    "# Embedding generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84bc58ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0h/q4qdtr9j7g791902612bqpgh0000gn/T/ipykernel_76636/4188097725.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "/Users/victor/Documents/Documents - Victorâ€™s MacBook Air (2)/ai_project/RAG_AI_venv/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "embeddings = embedding_model.embed_documents([text.page_content for text in texts])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44420a89",
   "metadata": {},
   "source": [
    "# Vector Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a9dce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(texts, embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5319b66f",
   "metadata": {},
   "source": [
    "# Retreival and response generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2ebf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# setting up the llm using the api key from goettingen\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=os.getenv(\"API_KEY\"),\n",
    "    openai_api_base=\"https://chat-ai.academiccloud.de/v1\",\n",
    "    model_name=\"meta-llama-3.1-8b-instruct\",\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3b06b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6167048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0h/q4qdtr9j7g791902612bqpgh0000gn/T/ipykernel_76636/3321119944.py:2: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      " The main topics in the text are:\n",
      "\n",
      "1. Discursive politics of environmental reproductive justice\n",
      "2. The importance of centering community voices in policy-making\n",
      "3. The role of language and discourse in shaping social and political meaning\n",
      "4. The application of a critical, interpretive, and discursive approach to the study of politics and public administration.\n",
      "\n",
      "Overall, the text appears to be discussing the ways in which language and discourse can be used to shape policy and maintain power, and the importance of amplifying marginalized voices in policy-making.\n",
      "\n",
      "Sources:\n",
      " [Document(id='62909f6d-f2d2-4b7b-9da7-93bb50438333')]
    }
   ],
   "source": [
    "query = \"What are the main topics in the text?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(\"Answer:\\n\", result[\"result\"])\n",
    "print(\"\\nSources:\\n\", result[\"source_documents\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
